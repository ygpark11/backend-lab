import time
import json
import requests
import traceback
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# 1. ì„¤ì •
JAVA_API_URL = "http://localhost:8080/api/v1/games/collect"
LIST_PAGE_URL = "https://store.playstation.com/ko-kr/category/3f772501-f6f8-49b7-abac-874a88ca4897/1"

def run_batch_crawler():
    print("ğŸš€ [ì§€ëŠ¥í˜• ìˆ˜ì§‘ê¸° Level 17+] ê°€ë™! (Full Fields)")

    options = webdriver.ChromeOptions()
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--lang=ko-KR")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    wait = WebDriverWait(driver, 15)

    try:
        # Phase A: ëª©ë¡ ìˆ˜ì§‘
        print(f"ğŸ“‚ ëª©ë¡ í˜ì´ì§€ ì ‘ì†: {LIST_PAGE_URL}")
        driver.get(LIST_PAGE_URL)
        time.sleep(5)

        print("ğŸ” ê²Œì„ ë§í¬ ìˆ˜ì§‘ ì¤‘...")
        driver.execute_script("window.scrollTo(0, 2000);")
        time.sleep(2)

        link_elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/product/']")
        game_urls = []
        for el in link_elements:
            url = el.get_attribute("href")
            if url and "/ko-kr/product/" in url:
                if url not in game_urls:
                    game_urls.append(url)

        target_urls = game_urls[:5] # í…ŒìŠ¤íŠ¸ìš© 5ê°œ
        print(f"ğŸ“œ ì´ {len(game_urls)}ê°œ ì¤‘ {len(target_urls)}ê°œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

        # Phase B: ìƒì„¸ ìˆ˜ì§‘
        for index, game_url in enumerate(target_urls):
            print(f"\n[{index+1}/{len(target_urls)}] ìƒì„¸ í˜ì´ì§€ ì´ë™: {game_url}")
            crawl_detail_and_send(driver, wait, game_url)
            time.sleep(2)

    except Exception:
        traceback.print_exc()
    finally:
        driver.quit()
        print("ğŸ‘‹ í¬ë¡¤ë§ ì¢…ë£Œ.")

def crawl_detail_and_send(driver, wait, target_url):
    try:
        driver.get(target_url)
        time.sleep(3)

        # 1. ì œëª©
        try:
            title_element = wait.until(EC.presence_of_element_located(
                (By.CSS_SELECTOR, "[data-qa='mfe-game-title#name']")
            ))
            title = title_element.text
        except:
            title = "Unknown Title"

        # 2. ì¥ë¥´ (Genre) - [New]
        genre_ids = ""
        try:
            # ìƒì„¸ í˜ì´ì§€ í•˜ë‹¨ ì •ë³´ ì„¹ì…˜ì—ì„œ ì¥ë¥´ íƒœê·¸ ì°¾ê¸°
            genre_element = driver.find_element(By.CSS_SELECTOR, "[data-qa='gameInfo#releaseInformation#genre-value']")
            genre_ids = genre_element.text # "ì•¡ì…˜, RPG" í˜•íƒœë¡œ ê°€ì ¸ì˜´
        except:
            pass # ì¥ë¥´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´

        # 3. ê°€ê²© ë° ìƒì„¸ ì •ë³´
        current_price = 0
        original_price = 0
        discount_rate = 0
        sale_end_date = None
        is_plus_exclusive = False # [New] Plus íšŒì› ì „ìš© ì—¬ë¶€

        found_valid_offer = False

        for i in range(3):
            try:
                # [Step A] íŒë§¤ê°€
                price_selector = f"[data-qa='mfeCtaMain#offer{i}#finalPrice']"
                price_element = driver.find_element(By.CSS_SELECTOR, price_selector)
                price_text = price_element.text
                clean_price = re.sub(r'[^0-9]', '', price_text)

                if not clean_price or int(clean_price) == 0:
                    continue

                current_price = int(clean_price)
                found_valid_offer = True

                # [Step B] ì •ê°€ (Original Price)
                try:
                    orig_selector = f"[data-qa='mfeCtaMain#offer{i}#originalPrice']"
                    orig_element = driver.find_element(By.CSS_SELECTOR, orig_selector)
                    original_price = int(re.sub(r'[^0-9]', '', orig_element.text))
                except:
                    original_price = current_price

                # [Step C] í• ì¸ìœ¨ & ì¢…ë£Œì¼
                try:
                    discount_sel = f"[data-qa='mfeCtaMain#offer{i}#discountInfo']"
                    discount_elem = driver.find_element(By.CSS_SELECTOR, discount_sel)
                    raw_rate = discount_elem.text
                    discount_rate = int(re.sub(r'[^0-9]', '', raw_rate))

                    date_sel = f"[data-qa='mfeCtaMain#offer{i}#discountDescriptor']"
                    date_elem = driver.find_element(By.CSS_SELECTOR, date_sel)
                    raw_date = date_elem.text.split(" ")[0]
                    dt = datetime.strptime(raw_date, "%Y/%m/%d")
                    sale_end_date = dt.strftime("%Y-%m-%d")
                except:
                    pass

                # [Step D] PS Plus ì „ìš© í• ì¸ ì—¬ë¶€ í™•ì¸ - [New]
                # ë³´í†µ í• ì¸ íƒœê·¸ë‚˜ ê°€ê²© ì£¼ë³€ì— 'PlayStation Plus' í…ìŠ¤íŠ¸ í˜¹ì€ ì•„ì´ì½˜ì´ ìˆìŒ.
                # data-qa='mfeCtaMain#offer0#discountInfo' í…ìŠ¤íŠ¸ ì•ˆì— "Plus"ê°€ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜,
                # ë³„ë„ì˜ ì„œë¹„ìŠ¤ ë¼ë²¨(serviceLabel)ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                try:
                    # ë°©ë²• 1: ì„œë¹„ìŠ¤ ë¼ë²¨ í™•ì¸ (ë…¸ë€ìƒ‰ í”ŒëŸ¬ìŠ¤ ë§ˆí¬)
                    service_label_sel = f"[data-qa='mfeCtaMain#offer{i}#serviceLabel']"
                    driver.find_element(By.CSS_SELECTOR, service_label_sel)
                    is_plus_exclusive = True
                except:
                    # ë°©ë²• 2: í• ì¸ ë¬¸êµ¬ì— 'Plus'ê°€ ìˆëŠ”ì§€ í™•ì¸
                    try:
                        if "Plus" in discount_elem.text:
                            is_plus_exclusive = True
                    except:
                        is_plus_exclusive = False

                break

            except:
                continue

        if not found_valid_offer:
            print(f"   â„¹ï¸ ê°€ê²© ì •ë³´ ì—†ìŒ: {title}")
            return

        # 4. ì´ë¯¸ì§€
        image_url = ""
        try:
            image_element = driver.find_element(By.CSS_SELECTOR, "img[data-qa='gameBackgroundImage#heroImage#image']")
            image_url = image_element.get_attribute("src").split("?")[0]
        except:
            pass

        # 5. ì „ì†¡
        ps_store_id = target_url.split("/")[-1].split("?")[0]

        payload = {
            "psStoreId": ps_store_id,
            "title": title,
            "publisher": "Batch Crawler",
            "imageUrl": image_url,
            "description": "Full Data Crawler",
            "originalPrice": original_price,
            "currentPrice": current_price,
            "discountRate": discount_rate,
            "saleEndDate": sale_end_date,
            "genreIds": genre_ids,          # [New]
            "isPlusExclusive": is_plus_exclusive # [New]
        }

        res = requests.post(JAVA_API_URL, data=json.dumps(payload), headers={'Content-Type': 'application/json'})
        if res.status_code == 200:
            plus_mark = " [PS+]" if is_plus_exclusive else ""
            print(f"   âœ… [ì„±ê³µ] {title} | {genre_ids}{plus_mark}")
        else:
            print(f"   ğŸ’¥ [ì‹¤íŒ¨] ì„œë²„ ì‘ë‹µ: {res.status_code}")

    except Exception as e:
        print(f"   âš ï¸ ìˆ˜ì§‘ ì‹¤íŒ¨ ({target_url}): {e}")

if __name__ == "__main__":
    run_batch_crawler()