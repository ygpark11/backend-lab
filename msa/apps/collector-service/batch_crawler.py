import os # [New] í™˜ê²½ë³€ìˆ˜ ì½ê¸° ìœ„í•´ ì¶”ê°€
import time
import json
import requests
import traceback
import re
import threading  # [New] ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•´ í•„ìš”
from datetime import datetime
from flask import Flask, jsonify # [New] ì›¹ ì„œë²„ ê¸°ëŠ¥

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- [ì„¤ì •] ---
app = Flask(__name__) # Flask ì•± ìƒì„±

BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8080")
JAVA_API_URL = f"{BASE_URL}/api/v1/games/collect"
TARGET_API_URL = f"{BASE_URL}/api/v1/games/targets"
SELENIUM_URL = os.getenv("SELENIUM_URL")
LIST_PAGE_URL = "https://store.playstation.com/ko-kr/category/3f772501-f6f8-49b7-abac-874a88ca4897/1"

# í¬ë¡¤ë§ ì¤‘ì¸ì§€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸ (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
is_running = False

def fetch_update_targets():
    """Java ì„œë²„ì—ì„œ ê°±ì‹  í•„ìš”í•œ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        res = requests.get(TARGET_API_URL)
        if res.status_code == 200:
            return res.json()
        return []
    except Exception as e:
        print(f"âš ï¸ Java ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return []

def run_batch_crawler_logic():
    global is_running
    print("ğŸš€ [ì§€ëŠ¥í˜• ìˆ˜ì§‘ê¸°] ì¶œê²© ì¤€ë¹„ ì¤‘...")

    options = webdriver.ChromeOptions()
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--lang=ko-KR")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    # options.add_argument("--headless") # Grid ì‚¬ìš© ì‹œì—” êµ³ì´ ì•ˆ í•´ë„ ë¨ (Gridê°€ ì•Œì•„ì„œ í•¨)

    driver = None
    try:
        # 1. ë“œë¼ì´ë²„ ì—°ê²°
        if SELENIUM_URL:
            print(f"ğŸŒ [Docker Mode] Selenium Grid({SELENIUM_URL})ì— ì—°ê²°í•©ë‹ˆë‹¤...")
            driver = webdriver.Remote(
                command_executor=SELENIUM_URL,
                options=options
            )
        else:
            print("ğŸ’» [Local Mode] ë¡œì»¬ Chrome Driverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        wait = WebDriverWait(driver, 15)
        visited_urls = set()

        # 2. [Phase 1] Target Update
        targets = fetch_update_targets()
        if targets:
            print(f"ğŸ¯ [Target Update] {len(targets)}ê°œ ê°±ì‹  ì‹œì‘")
            for url in targets:
                crawl_detail_and_send(driver, wait, url)
                visited_urls.add(url)
                time.sleep(2)

        # 3. [Phase 2] Discovery
        print(f"ğŸ“‚ [Discovery] ì‹ ê·œ íƒìƒ‰ ì‹œì‘")
        driver.get(LIST_PAGE_URL)
        time.sleep(5)
        driver.execute_script("window.scrollTo(0, 2000);")
        time.sleep(2)

        link_elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/product/']")
        discovered_urls = []
        for el in link_elements:
            try:
                url = el.get_attribute("href")
                if url and "/ko-kr/product/" in url and url not in visited_urls:
                    if url not in discovered_urls:
                        discovered_urls.append(url)
            except: continue

        count = 0
        for url in discovered_urls:
            if count >= 30: break
            crawl_detail_and_send(driver, wait, url)
            visited_urls.add(url)
            count += 1
            time.sleep(2)

        print(f"ğŸ‘‹ í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ. (ì´ {len(visited_urls)}ê°œ ì²˜ë¦¬)")

    except Exception:
        traceback.print_exc()
    finally:
        # ë“œë¼ì´ë²„ê°€ ì¼œì ¸ ìˆë‹¤ë©´ ë„ê³ , ì‹¤í–‰ ìƒíƒœ í•´ì œ
        if driver:
            driver.quit()
        is_running = False

        print(f"ğŸ‘‹ í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ. (ì´ {len(visited_urls)}ê°œ ì²˜ë¦¬)")

def crawl_detail_and_send(driver, wait, target_url):
    # ... (ê¸°ì¡´ ìƒì„¸ ìˆ˜ì§‘ ë¡œì§ê³¼ 100% ë™ì¼, ìƒëµ ì—†ì´ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤) ...
    # í¸ì˜ë¥¼ ìœ„í•´ ì´ í•¨ìˆ˜ ë‚´ë¶€ëŠ” ì„ ì¥ë‹˜ì˜ ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”.
    # ë³µë¶™í•˜ê¸° ì–´ë ¤ìš°ì‹œë©´ ì•„ë˜ì— ë‹¤ì‹œ ì ì–´ë“œë¦´ê¹Œìš”?
    # (ì¼ë‹¨ ì•„ê¹Œ ì„±ê³µí•œ ì½”ë“œì˜ ì´ í•¨ìˆ˜ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤.)
    try:
        driver.get(target_url)
        time.sleep(3)
        # 1. ì œëª©
        try:
            title_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "[data-qa='mfe-game-title#name']")))
            title = title_element.text
        except: return

        # 2. ì¥ë¥´
        genre_ids = ""
        try:
            genre_element = driver.find_element(By.CSS_SELECTOR, "[data-qa='gameInfo#releaseInformation#genre-value']")
            genre_ids = genre_element.text
        except: pass

        # 3. ê°€ê²©
        current_price = 0; original_price = 0; discount_rate = 0
        sale_end_date = None; is_plus_exclusive = False; found_valid_offer = False

        for i in range(3):
            try:
                price_elem = driver.find_element(By.CSS_SELECTOR, f"[data-qa='mfeCtaMain#offer{i}#finalPrice']")
                clean_price = re.sub(r'[^0-9]', '', price_elem.text)
                if not clean_price or int(clean_price) == 0: continue
                current_price = int(clean_price)
                found_valid_offer = True

                try:
                    orig_elem = driver.find_element(By.CSS_SELECTOR, f"[data-qa='mfeCtaMain#offer{i}#originalPrice']")
                    original_price = int(re.sub(r'[^0-9]', '', orig_elem.text))
                except: original_price = current_price

                try:
                    disc_elem = driver.find_element(By.CSS_SELECTOR, f"[data-qa='mfeCtaMain#offer{i}#discountInfo']")
                    discount_rate = int(re.sub(r'[^0-9]', '', disc_elem.text))
                    date_elem = driver.find_element(By.CSS_SELECTOR, f"[data-qa='mfeCtaMain#offer{i}#discountDescriptor']")
                    sale_end_date = datetime.strptime(date_elem.text.split(" ")[0], "%Y/%m/%d").strftime("%Y-%m-%d")
                except: pass

                try:
                    driver.find_element(By.CSS_SELECTOR, f"[data-qa='mfeCtaMain#offer{i}#serviceLabel']")
                    is_plus_exclusive = True
                except:
                    if "Plus" in disc_elem.text: is_plus_exclusive = True
                break
            except: continue

        if not found_valid_offer: pass

        # 4. ì´ë¯¸ì§€
        image_url = ""
        try:
            img_elem = driver.find_element(By.CSS_SELECTOR, "img[data-qa='gameBackgroundImage#heroImage#image']")
            image_url = img_elem.get_attribute("src").split("?")[0]
        except: pass

        # 5. ì „ì†¡
        ps_store_id = target_url.split("/")[-1].split("?")[0]
        payload = {
            "psStoreId": ps_store_id, "title": title, "publisher": "Batch Crawler",
            "imageUrl": image_url, "description": "Full Data Crawler",
            "originalPrice": original_price, "currentPrice": current_price,
            "discountRate": discount_rate, "saleEndDate": sale_end_date,
            "genreIds": genre_ids, "isPlusExclusive": is_plus_exclusive
        }
        res = requests.post(JAVA_API_URL, data=json.dumps(payload), headers={'Content-Type': 'application/json'})
        if res.status_code == 200:
            print(f"   ğŸ†— [ì„±ê³µ] {title}")
        else:
            print(f"   ğŸ’¥ [ì‹¤íŒ¨] {res.status_code}")
    except Exception as e:
        print(f"   âš ï¸ ì‹¤íŒ¨: {e}")

# --- [API ì—”ë“œí¬ì¸íŠ¸] ---
@app.route('/run', methods=['POST'])
def trigger_crawl():
    global is_running
    if is_running:
        return jsonify({"status": "error", "message": "Crawler is already running"}), 409

    is_running = True
    # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (ìš”ì²­ìì—ê²ŒëŠ” ë°”ë¡œ ì‘ë‹µì„ ì£¼ê¸° ìœ„í•¨)
    thread = threading.Thread(target=run_batch_crawler_logic)
    thread.start()

    return jsonify({"status": "success", "message": "Crawler started"}), 200

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "UP", "crawler_running": is_running}), 200

if __name__ == "__main__":
    # 5000ë²ˆ í¬íŠ¸ì—ì„œ ëŒ€ê¸°
    print("ğŸ‘‚ [Collector] ëª…ë ¹ ëŒ€ê¸° ì¤‘ (Port 5000)...")
    app.run(host="0.0.0.0", port=5000)