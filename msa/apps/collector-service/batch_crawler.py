import time
import json
import requests
import traceback
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# 1. ì„¤ì •
JAVA_API_URL = "http://localhost:8080/api/v1/games/collect"
# PS5 ì „ì²´ ê²Œì„ ëª©ë¡ í˜ì´ì§€
LIST_PAGE_URL = "https://store.playstation.com/ko-kr/category/d71e8e6d-0940-4e03-bd02-404fc7d31a31/1"

def run_batch_crawler():
    print("ğŸš€ [ëŒ€ëŸ‰ ìˆ˜ì§‘ê¸°] ê°€ë™! ë¸Œë¼ìš°ì €ë¥¼ ì—½ë‹ˆë‹¤...")

    options = webdriver.ChromeOptions()
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--lang=ko-KR")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    wait = WebDriverWait(driver, 10)

    try:
        # ---------------------------------------------------------
        # Phase A: ëª©ë¡ í˜ì´ì§€ì—ì„œ "ë³´ë¬¼ ì§€ë„(URL ëª©ë¡)" í™•ë³´
        # ---------------------------------------------------------
        print(f"ğŸ“‚ ëª©ë¡ í˜ì´ì§€ ì ‘ì†: {LIST_PAGE_URL}")
        driver.get(LIST_PAGE_URL)
        print("   -> 5ì´ˆê°„ ë Œë”ë§ ëŒ€ê¸°...")
        time.sleep(5)

        print("ğŸ” ê²Œì„ ë§í¬ ìˆ˜ì§‘ ì¤‘...")

        # â˜… [í•µì‹¬ ìˆ˜ì •] ì„ ì¥ì´ ì°¾ì€ href íŒ¨í„´ì„ ì´ìš©í•œ ê°•ë ¥í•œ í•„í„°ë§
        # CSS Selector ì„¤ëª…: "a íƒœê·¸ì¸ë°, href ì†ì„±ì— '/product/' ê¸€ìê°€ í¬í•¨ëœ ë†ˆ ë‹¤ ë‚˜ì™€!"
        link_elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/product/']")

        game_urls = []
        for el in link_elements:
            url = el.get_attribute("href")
            # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ í•œ ë²ˆ ë” ê²€ì¦ + ì¤‘ë³µ ì œê±°
            if url and "/ko-kr/product/" in url:
                if url not in game_urls:
                    game_urls.append(url)

        print(f"ğŸ“œ ì´ {len(game_urls)}ê°œì˜ ê²Œì„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")

        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìƒìœ„ 3ê°œë§Œ í„¸ì–´ë´…ì‹œë‹¤. (ë¶‰ì€ì‚¬ë§‰ ë“±)
        target_urls = game_urls[:3]
        print(f"ğŸ¯ ì˜¤ëŠ˜ì€ ìƒìœ„ {len(target_urls)}ê°œë§Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

        # ---------------------------------------------------------
        # Phase B: ê° í˜ì´ì§€ ìˆœíšŒ (Loop)
        # ---------------------------------------------------------
        for index, game_url in enumerate(target_urls):
            print(f"\n[{index+1}/{len(target_urls)}] ìƒì„¸ í˜ì´ì§€ ì´ë™: {game_url}")
            crawl_detail_and_send(driver, wait, game_url)
            time.sleep(2) # ë§¤ë„ˆ íœ´ì‹

    except Exception:
        traceback.print_exc()
    finally:
        driver.quit()
        print("ğŸ‘‹ í¬ë¡¤ë§ ì¢…ë£Œ.")

def crawl_detail_and_send(driver, wait, target_url):
    """
    ë‹¨ê±´ ìˆ˜ì§‘ ë¡œì§ (ì–´ì œ ì™„ì„±í•œ ë¡œì§ ì¬ì‚¬ìš©)
    """
    try:
        driver.get(target_url)
        time.sleep(3) # ìƒì„¸ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

        # 1. ì œëª©
        title_element = wait.until(EC.presence_of_element_located(
            (By.CSS_SELECTOR, "[data-qa='mfe-game-title#name']")
        ))
        title = title_element.text

        # 2. ê°€ê²© (ë¬´ë£Œ ê²Œì„ ì˜ˆì™¸ì²˜ë¦¬ í¬í•¨)
        try:
            price_element = driver.find_element(By.CSS_SELECTOR, "[data-qa='mfeCtaMain#offer0#finalPrice']")
            price_text = price_element.text
        except:
            price_text = "0"
            print("   -> ê°€ê²© ì •ë³´ ì—†ìŒ/ë¬´ë£Œ")

        # 3. ì´ë¯¸ì§€ (ì„ ì¥ì´ ì°¾ì€ íƒœê·¸ ì ìš©)
        image_url = ""
        try:
            image_element = driver.find_element(By.CSS_SELECTOR, "img[data-qa='gameBackgroundImage#heroImage#image']")
            image_url = image_element.get_attribute("src").split("?")[0]
        except:
            pass

        # 4. ì •ì œ
        current_price = int(price_text.replace("â‚©", "").replace("ì›", "").replace(",", "").replace(" ", ""))
        ps_store_id = target_url.split("/")[-1]

        # 5. ì „ì†¡
        payload = {
            "psStoreId": ps_store_id,
            "title": title,
            "publisher": "Batch Crawler",
            "imageUrl": image_url,
            "currentPrice": current_price,
            "isDiscount": False,
            "discountRate": 0
        }

        res = requests.post(JAVA_API_URL, data=json.dumps(payload), headers={'Content-Type': 'application/json'})
        if res.status_code == 200:
            print(f"   âœ… [ì„±ê³µ] ì €ì¥ ì™„ë£Œ: {title} ({current_price}ì›)")
        else:
            print(f"   ğŸ’¥ [ì‹¤íŒ¨] ì„œë²„ ì‘ë‹µ: {res.status_code}")

    except Exception as e:
        print(f"   âš ï¸ ìˆ˜ì§‘ ì‹¤íŒ¨ ({target_url}): {e}")

if __name__ == "__main__":
    run_batch_crawler()